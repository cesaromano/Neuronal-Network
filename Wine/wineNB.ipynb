{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
      "0      1    14.23        1.71  2.43               15.6        127   \n",
      "1      1    13.20        1.78  2.14               11.2        100   \n",
      "2      1    13.16        2.36  2.67               18.6        101   \n",
      "3      1    14.37        1.95  2.50               16.8        113   \n",
      "4      1    13.24        2.59  2.87               21.0        118   \n",
      "\n",
      "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
      "0           2.80        3.06                  0.28             2.29   \n",
      "1           2.65        2.76                  0.26             1.28   \n",
      "2           2.80        3.24                  0.30             2.81   \n",
      "3           3.85        3.49                  0.24             2.18   \n",
      "4           2.80        2.69                  0.39             1.82   \n",
      "\n",
      "   Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
      "0             5.64  1.04                          3.92     1065  \n",
      "1             4.38  1.05                          3.40     1050  \n",
      "2             5.68  1.03                          3.17     1185  \n",
      "3             7.80  0.86                          3.45     1480  \n",
      "4             4.32  1.04                          2.93      735   (178, 14)\n"
     ]
    }
   ],
   "source": [
    "filePath = 'wine.data' #getting data path\n",
    "\n",
    "data = pd.read_csv(filePath, names=[\"label\", \n",
    "        \"Alcohol\", \"Malic acid\", \"Ash\", \n",
    "\t    \"Alcalinity of ash\", \"Magnesium\",\n",
    "\t    \"Total phenols\", \"Flavanoids\",\n",
    " \t    \"Nonflavanoid phenols\", \"Proanthocyanins\",\n",
    "\t    \"Color intensity\", \"Hue\", \"OD280/OD315 of diluted wines\",\n",
    " \t    \"Proline\"]) #read data from pandas\n",
    "print(data.head(), data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     label  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
      "59       2    12.37        0.94  1.36               10.6         88   \n",
      "128      2    12.37        1.63  2.30               24.5         88   \n",
      "84       2    11.84        0.89  2.58               18.0         94   \n",
      "86       2    12.16        1.61  2.31               22.8         90   \n",
      "129      2    12.04        4.30  2.38               22.0         80   \n",
      "\n",
      "     Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
      "59            1.98        0.57                  0.28             0.42   \n",
      "128           2.22        2.45                  0.40             1.90   \n",
      "84            2.20        2.21                  0.22             2.35   \n",
      "86            1.78        1.69                  0.43             1.56   \n",
      "129           2.10        1.75                  0.42             1.35   \n",
      "\n",
      "     Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
      "59              1.95  1.05                          1.82      520  \n",
      "128             2.12  0.89                          2.78      342  \n",
      "84              3.05  0.79                          3.08      520  \n",
      "86              2.45  1.33                          2.26      495  \n",
      "129             2.60  0.79                          2.57      580   (178, 14)\n"
     ]
    }
   ],
   "source": [
    "data = shuffle(data) #shuffling data\n",
    "print(data.head(), data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59     2\n",
      "128    2\n",
      "84     2\n",
      "86     2\n",
      "129    2\n",
      "Name: label, dtype: int64      Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  Total phenols  \\\n",
      "59     12.37        0.94  1.36               10.6         88           1.98   \n",
      "128    12.37        1.63  2.30               24.5         88           2.22   \n",
      "84     11.84        0.89  2.58               18.0         94           2.20   \n",
      "86     12.16        1.61  2.31               22.8         90           1.78   \n",
      "129    12.04        4.30  2.38               22.0         80           2.10   \n",
      "\n",
      "     Flavanoids  Nonflavanoid phenols  Proanthocyanins  Color intensity   Hue  \\\n",
      "59         0.57                  0.28             0.42             1.95  1.05   \n",
      "128        2.45                  0.40             1.90             2.12  0.89   \n",
      "84         2.21                  0.22             2.35             3.05  0.79   \n",
      "86         1.69                  0.43             1.56             2.45  1.33   \n",
      "129        1.75                  0.42             1.35             2.60  0.79   \n",
      "\n",
      "     OD280/OD315 of diluted wines  Proline  \n",
      "59                           1.82      520  \n",
      "128                          2.78      342  \n",
      "84                           3.08      520  \n",
      "86                           2.26      495  \n",
      "129                          2.57      580  \n"
     ]
    }
   ],
   "source": [
    "features = data.drop(['label'], axis=1) #getting the training features\n",
    "labels = data['label'] #getting the training labels\n",
    "print(labels.head(), features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]]      Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  Total phenols  \\\n",
      "59     12.37        0.94  1.36               10.6         88           1.98   \n",
      "128    12.37        1.63  2.30               24.5         88           2.22   \n",
      "84     11.84        0.89  2.58               18.0         94           2.20   \n",
      "86     12.16        1.61  2.31               22.8         90           1.78   \n",
      "129    12.04        4.30  2.38               22.0         80           2.10   \n",
      "\n",
      "     Flavanoids  Nonflavanoid phenols  Proanthocyanins  Color intensity   Hue  \\\n",
      "59         0.57                  0.28             0.42             1.95  1.05   \n",
      "128        2.45                  0.40             1.90             2.12  0.89   \n",
      "84         2.21                  0.22             2.35             3.05  0.79   \n",
      "86         1.69                  0.43             1.56             2.45  1.33   \n",
      "129        1.75                  0.42             1.35             2.60  0.79   \n",
      "\n",
      "     OD280/OD315 of diluted wines  Proline  \n",
      "59                           1.82      520  \n",
      "128                          2.78      342  \n",
      "84                           3.08      520  \n",
      "86                           2.26      495  \n",
      "129                          2.57      580  \n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder() #instantiate encoder class to encode labels\n",
    "lEncoded = encoder.fit_transform(labels) #fitting and transforming data\n",
    "labelsE = pd.get_dummies(lEncoded).values #encoding labels\n",
    "print(labelsE[:5], features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59     2\n",
      "128    2\n",
      "84     2\n",
      "86     2\n",
      "129    2\n",
      "Name: label, dtype: int64      Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  Total phenols  \\\n",
      "59     12.37        0.94  1.36               10.6         88           1.98   \n",
      "128    12.37        1.63  2.30               24.5         88           2.22   \n",
      "84     11.84        0.89  2.58               18.0         94           2.20   \n",
      "86     12.16        1.61  2.31               22.8         90           1.78   \n",
      "129    12.04        4.30  2.38               22.0         80           2.10   \n",
      "\n",
      "     Flavanoids  Nonflavanoid phenols  Proanthocyanins  Color intensity   Hue  \\\n",
      "59         0.57                  0.28             0.42             1.95  1.05   \n",
      "128        2.45                  0.40             1.90             2.12  0.89   \n",
      "84         2.21                  0.22             2.35             3.05  0.79   \n",
      "86         1.69                  0.43             1.56             2.45  1.33   \n",
      "129        1.75                  0.42             1.35             2.60  0.79   \n",
      "\n",
      "     OD280/OD315 of diluted wines  Proline  \n",
      "59                           1.82      520  \n",
      "128                          2.78      342  \n",
      "84                           3.08      520  \n",
      "86                           2.26      495  \n",
      "129                          2.57      580  \n"
     ]
    }
   ],
   "source": [
    "features = data.drop(['label'], axis=1) #getting the training features\n",
    "labels = data['label'] #getting the training labels\n",
    "print(labels.head(), features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Alcohol  Malic acid       Ash  Alcalinity of ash  Magnesium  \\\n",
      "59  -0.778980   -1.253450 -3.679162          -2.671018  -0.824415   \n",
      "128 -0.778980   -0.634063 -0.243142           1.502943  -0.824415   \n",
      "84  -1.433671   -1.298334  0.780354          -0.448909  -0.403135   \n",
      "86  -1.038386   -0.652016 -0.206588           0.992459  -0.683988   \n",
      "129 -1.186618    1.762698  0.049285           0.752231  -1.386122   \n",
      "\n",
      "     Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
      "59       -0.504914   -1.465058             -0.659563        -2.051513   \n",
      "128      -0.120355    0.422399              0.307374         0.541571   \n",
      "84       -0.152402    0.181447             -1.143031         1.330009   \n",
      "86       -0.825381   -0.340615              0.549108        -0.054137   \n",
      "129      -0.312635   -0.280377              0.468530        -0.422075   \n",
      "\n",
      "     Color intensity       Hue  OD280/OD315 of diluted wines   Proline  \n",
      "59         -1.344466  0.406051                     -1.118210 -0.722540  \n",
      "128        -1.270929 -0.295924                      0.237735 -1.289380  \n",
      "84         -0.868639 -0.734657                      0.661468 -0.722540  \n",
      "86         -1.128181  1.634506                     -0.496736 -0.802153  \n",
      "129        -1.063296 -0.734657                     -0.058878 -0.531471  \n"
     ]
    }
   ],
   "source": [
    "#zscore\n",
    "features = features.select_dtypes(include='number').apply(zscore)\n",
    "print(features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124, 13) (26, 13) (28, 13)\n",
      "(124, 3) (26, 3) (28, 3)\n"
     ]
    }
   ],
   "source": [
    "fd = int(.7*len(data)) #Getting first split index point of division \n",
    "sd = fd+int(.15*len(data)) #Getting second split index point of division\n",
    "\n",
    "trainF, validationF, testF = np.split(features, [fd, sd]) #split data in train, test and validation sets\n",
    "trainLE, validationLE, testLE = np.split(labelsE, [fd, sd]) #split data in train, test and validation sets\n",
    "print(trainF.shape, validationF.shape, testF.shape)\n",
    "print(trainLE.shape, validationLE.shape, testLE.shape)\n",
    "#print(validationLE[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 13)                182       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 3)                 42        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 224\n",
      "Trainable params: 224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\guazo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() #instantiate the Sequential module to create the model\n",
    "#model.add(Dense(13, input_shape=(13,), activation='relu')) #adding an input layer of 4 perceptrons and as a activation function relu\n",
    "#model.add(Dense(13, kernel_initializer='zeros', input_shape=(13,), activation='relu')) #adding an input layer of 4 perceptrons and as a activation function relu\n",
    "model.add(Dense(13, kernel_initializer='ones', input_shape=(13,), activation='relu')) #adding an input layer of 4 perceptrons and as a activation function relu\n",
    "model.add(Dense(3, activation='softmax')) #adding the output layer\n",
    "model.compile(Adam(lr=0.2), 'categorical_crossentropy', metrics=['accuracy']) #definning the learning rate\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 2s 160ms/step - loss: 2.1445 - accuracy: 0.3871 - val_loss: 2.4352 - val_accuracy: 0.7692\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 1.7659 - accuracy: 0.8548 - val_loss: 1.0138 - val_accuracy: 0.8846\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7339 - accuracy: 0.9355 - val_loss: 0.3256 - val_accuracy: 0.9615\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.3542 - accuracy: 0.9597 - val_loss: 0.0339 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1230 - accuracy: 0.9839 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.0452 - accuracy: 0.9758 - val_loss: 0.0292 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0511 - accuracy: 0.9758 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 9.9217e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 9.4891e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 9.1010e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 8.7533e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 8.4741e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 8.1904e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 7.9367e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 7.7125e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 7.4913e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 7.2849e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 7.0960e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 6.8904e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 6.7180e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 6.5513e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 6.3779e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 6.2159e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 6.0635e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 5.9251e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.7758e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 5.6424e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 5.5119e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 5.3785e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 5.2651e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 5.1347e-04 - accuracy: 1.0000 - val_loss: 9.9509e-04 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 5.0069e-04 - accuracy: 1.0000 - val_loss: 9.7644e-04 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 4.9056e-04 - accuracy: 1.0000 - val_loss: 9.5785e-04 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 4.8018e-04 - accuracy: 1.0000 - val_loss: 9.4065e-04 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 4.6964e-04 - accuracy: 1.0000 - val_loss: 9.2440e-04 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 4.5944e-04 - accuracy: 1.0000 - val_loss: 9.0907e-04 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.5044e-04 - accuracy: 1.0000 - val_loss: 8.9455e-04 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 4.4086e-04 - accuracy: 1.0000 - val_loss: 8.8120e-04 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 4.3359e-04 - accuracy: 1.0000 - val_loss: 8.6828e-04 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 4.2425e-04 - accuracy: 1.0000 - val_loss: 8.5598e-04 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.1529e-04 - accuracy: 1.0000 - val_loss: 8.4392e-04 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 4.0741e-04 - accuracy: 1.0000 - val_loss: 8.3166e-04 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 3.9828e-04 - accuracy: 1.0000 - val_loss: 8.1985e-04 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 3.9043e-04 - accuracy: 1.0000 - val_loss: 8.0867e-04 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.8261e-04 - accuracy: 1.0000 - val_loss: 7.9788e-04 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 3.7583e-04 - accuracy: 1.0000 - val_loss: 7.8740e-04 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 3.6867e-04 - accuracy: 1.0000 - val_loss: 7.7783e-04 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 3.6186e-04 - accuracy: 1.0000 - val_loss: 7.6895e-04 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 3.5583e-04 - accuracy: 1.0000 - val_loss: 7.6002e-04 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 3.4973e-04 - accuracy: 1.0000 - val_loss: 7.5161e-04 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 3.4408e-04 - accuracy: 1.0000 - val_loss: 7.4360e-04 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 3.3859e-04 - accuracy: 1.0000 - val_loss: 7.3593e-04 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.3284e-04 - accuracy: 1.0000 - val_loss: 7.2853e-04 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 3.2772e-04 - accuracy: 1.0000 - val_loss: 7.2153e-04 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 3.2312e-04 - accuracy: 1.0000 - val_loss: 7.1481e-04 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 3.1855e-04 - accuracy: 1.0000 - val_loss: 7.0812e-04 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 3.1286e-04 - accuracy: 1.0000 - val_loss: 7.0153e-04 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 3.0760e-04 - accuracy: 1.0000 - val_loss: 6.9506e-04 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 3.0211e-04 - accuracy: 1.0000 - val_loss: 6.8789e-04 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.9630e-04 - accuracy: 1.0000 - val_loss: 6.8008e-04 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 2.9031e-04 - accuracy: 1.0000 - val_loss: 6.7282e-04 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 2.8512e-04 - accuracy: 1.0000 - val_loss: 6.6543e-04 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 2.7980e-04 - accuracy: 1.0000 - val_loss: 6.5846e-04 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 2.7461e-04 - accuracy: 1.0000 - val_loss: 6.5187e-04 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 2.6958e-04 - accuracy: 1.0000 - val_loss: 6.4590e-04 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 2.6475e-04 - accuracy: 1.0000 - val_loss: 6.4005e-04 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 2.5842e-04 - accuracy: 1.0000 - val_loss: 6.3436e-04 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 2.5277e-04 - accuracy: 1.0000 - val_loss: 6.2922e-04 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 2.4825e-04 - accuracy: 1.0000 - val_loss: 6.2421e-04 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 2.4199e-04 - accuracy: 1.0000 - val_loss: 6.1947e-04 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 2.3746e-04 - accuracy: 1.0000 - val_loss: 6.1450e-04 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 2.3330e-04 - accuracy: 1.0000 - val_loss: 6.0951e-04 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 2.2794e-04 - accuracy: 1.0000 - val_loss: 6.0242e-04 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 2.2212e-04 - accuracy: 1.0000 - val_loss: 5.9514e-04 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 2.1829e-04 - accuracy: 1.0000 - val_loss: 5.8839e-04 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 2.1457e-04 - accuracy: 1.0000 - val_loss: 5.8140e-04 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 2.1019e-04 - accuracy: 1.0000 - val_loss: 5.7513e-04 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 2.0628e-04 - accuracy: 1.0000 - val_loss: 5.6931e-04 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 2.0305e-04 - accuracy: 1.0000 - val_loss: 5.6369e-04 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 2.0006e-04 - accuracy: 1.0000 - val_loss: 5.5794e-04 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.9636e-04 - accuracy: 1.0000 - val_loss: 5.5281e-04 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 1.9371e-04 - accuracy: 1.0000 - val_loss: 5.4779e-04 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 1.9107e-04 - accuracy: 1.0000 - val_loss: 5.4291e-04 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 1.8819e-04 - accuracy: 1.0000 - val_loss: 5.3843e-04 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 1.8604e-04 - accuracy: 1.0000 - val_loss: 5.3414e-04 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 1.8327e-04 - accuracy: 1.0000 - val_loss: 5.3051e-04 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.8113e-04 - accuracy: 1.0000 - val_loss: 5.2696e-04 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.7878e-04 - accuracy: 1.0000 - val_loss: 5.2340e-04 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "valSet = (validationF, validationLE)\n",
    "history = model.fit(trainF, trainLE, epochs=100, validation_data=valSet) #training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F68FF8D870> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[7.6709682e-08 4.8382289e-09 9.9999988e-01]\n",
      " [3.9514187e-08 4.2972554e-09 1.0000000e+00]\n",
      " [2.8931013e-10 7.9374209e-19 1.0000000e+00]\n",
      " [2.4161184e-06 9.9999750e-01 7.4072673e-08]\n",
      " [6.5443068e-11 0.0000000e+00 1.0000000e+00]\n",
      " [1.0000000e+00 1.1353664e-33 4.8147370e-16]\n",
      " [9.4118869e-01 5.7333473e-02 1.4777231e-03]\n",
      " [6.1970606e-04 9.9917114e-01 2.0920776e-04]\n",
      " [6.2089697e-14 5.1294286e-23 1.0000000e+00]\n",
      " [2.0641373e-03 9.9728537e-01 6.5055792e-04]]\n"
     ]
    }
   ],
   "source": [
    "labelPred = model.predict(testF)\n",
    "print(labelPred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 1 2 0 1 1 2 1 1 1 1 0 1 0 1 1 2 0 0 2 2 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "labelTestClass = np.argmax(testLE, axis=1)\n",
    "labelPredClass = np.argmax(labelPred, axis=1)\n",
    "print(labelTestClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95         9\n",
      "           1       1.00      0.91      0.95        11\n",
      "           2       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           0.96        28\n",
      "   macro avg       0.97      0.97      0.97        28\n",
      "weighted avg       0.97      0.96      0.96        28\n",
      "\n",
      "[[ 9  0  0]\n",
      " [ 1 10  0]\n",
      " [ 0  0  8]]\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(labelTestClass, labelPredClass)\n",
    "confMatrix = confusion_matrix(labelTestClass, labelPredClass)\n",
    "print(report)\n",
    "print(confMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='MAE (training data)')\n",
    "plt.plot(history.history['val_loss'], label='MAE (validation data)')\n",
    "plt.title('MAE wine data')\n",
    "plt.ylabel('MAE value')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "#cuentame que mas ha pasado mijo\n",
    "#aca hablando con mi viejo"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a749ce9e7f55799ed652412e343278838c2c048e73833d9c0011e1dd1316e4b4"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
