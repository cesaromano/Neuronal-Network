{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = 'Iris/iris.data' #getting data path\n",
    "newFile = 'Iris/iris-mixed.data' #path of new mixed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sl   sw   pl   pw            label\n",
      "0  5.1  3.5  1.4  0.2      Iris-setosa\n",
      "1  7.0  3.2  4.7  1.4  Iris-versicolor\n",
      "2  6.3  3.3  6.0  2.5   Iris-virginica\n",
      "3  4.9  3.0  1.4  0.2      Iris-setosa\n",
      "4  6.4  3.2  4.5  1.5  Iris-versicolor (150, 5)\n"
     ]
    }
   ],
   "source": [
    "filePath = 'iris-mixed.data' #renaming filepath\n",
    "\n",
    "data = pd.read_csv(filePath, names=[\"sl\", \"sw\", \"pl\", \"pw\", \"label\"]) #read data from pandas\n",
    "print(data.head(), data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        Iris-setosa\n",
      "1    Iris-versicolor\n",
      "2     Iris-virginica\n",
      "3        Iris-setosa\n",
      "4    Iris-versicolor\n",
      "Name: label, dtype: object     sl   sw   pl   pw\n",
      "0  5.1  3.5  1.4  0.2\n",
      "1  7.0  3.2  4.7  1.4\n",
      "2  6.3  3.3  6.0  2.5\n",
      "3  4.9  3.0  1.4  0.2\n",
      "4  6.4  3.2  4.5  1.5\n"
     ]
    }
   ],
   "source": [
    "features = data.drop(['label'], axis=1) #getting the training features\n",
    "labels = data['label'] #getting the training labels\n",
    "print(labels.head(), features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]]     sl   sw   pl   pw\n",
      "0  5.1  3.5  1.4  0.2\n",
      "1  7.0  3.2  4.7  1.4\n",
      "2  6.3  3.3  6.0  2.5\n",
      "3  4.9  3.0  1.4  0.2\n",
      "4  6.4  3.2  4.5  1.5\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder() #instantiate encoder class to encode labels\n",
    "lEncoded = encoder.fit_transform(labels) #fitting and transforming data\n",
    "labelsE = pd.get_dummies(lEncoded).values #encoding labels\n",
    "print(labelsE[:5], features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          Iris-setosa\n",
      "1      Iris-versicolor\n",
      "2       Iris-virginica\n",
      "3          Iris-setosa\n",
      "4      Iris-versicolor\n",
      "            ...       \n",
      "145    Iris-versicolor\n",
      "146     Iris-virginica\n",
      "147        Iris-setosa\n",
      "148    Iris-versicolor\n",
      "149     Iris-virginica\n",
      "Name: label, Length: 150, dtype: object\n",
      "      sl   sw   pl   pw\n",
      "0    5.1  3.5  1.4  0.2\n",
      "1    7.0  3.2  4.7  1.4\n",
      "2    6.3  3.3  6.0  2.5\n",
      "3    4.9  3.0  1.4  0.2\n",
      "4    6.4  3.2  4.5  1.5\n",
      "..   ...  ...  ...  ...\n",
      "145  5.1  2.5  3.0  1.1\n",
      "146  6.2  3.4  5.4  2.3\n",
      "147  5.0  3.3  1.4  0.2\n",
      "148  5.7  2.8  4.1  1.3\n",
      "149  5.9  3.0  5.1  1.8\n",
      "\n",
      "[150 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "trainLabel = data['label'] #getting the training labels\n",
    "trainFeat = data.drop(['label'], axis=1) #getting the training features\n",
    "\n",
    "print(trainLabel)\n",
    "print(trainFeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "fd = int(.7*len(data)) #Getting first split index point of division \n",
    "sd = fd+int(.15*len(data)) #Getting second split index point of division\n",
    "\n",
    "trainF, validationF, testF = np.split(features, [fd, sd]) #split data in train, test and validation sets\n",
    "trainLE, validationLE, testLE = np.split(labelsE, [fd, sd]) #split data in train, test and validation sets\n",
    "#print(trainF.shape, validationF.shape, testF.shape)\n",
    "#print(trainLE.shape, validationLE.shape, testLE.shape)\n",
    "print(validationLE[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 15        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35\n",
      "Trainable params: 35\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\guazo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() #instantiate the Sequential module to create the model\n",
    "#model.add(Dense(4, input_shape=(4,), activation='relu')) #adding an input layer of 4 perceptrons and as a activation function relu\n",
    "#model.add(Dense(4, kernel_initializer='zeros', input_shape=(4,), activation='relu')) #adding an input layer of 4 perceptrons and as a activation function relu\n",
    "model.add(Dense(4, kernel_initializer='ones', input_shape=(4,), activation='relu')) #adding an input layer of 4 perceptrons and as a activation function relu\n",
    "model.add(Dense(3, activation='softmax')) #adding the output layer\n",
    "model.compile(Adam(lr=0.2), 'categorical_crossentropy', metrics=['accuracy']) #definning the learning rate\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 2s 177ms/step - loss: 8.5555 - accuracy: 0.3429 - val_loss: 1.5456 - val_accuracy: 0.3182\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 2.3695 - accuracy: 0.4190 - val_loss: 1.7406 - val_accuracy: 0.3636\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.4805 - accuracy: 0.5238 - val_loss: 0.8475 - val_accuracy: 0.6364\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 1.0553 - accuracy: 0.6190 - val_loss: 0.6290 - val_accuracy: 0.6818\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.6477 - accuracy: 0.7429 - val_loss: 0.8591 - val_accuracy: 0.6818\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.7160 - accuracy: 0.6762 - val_loss: 0.6141 - val_accuracy: 0.6818\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6688 - accuracy: 0.6667 - val_loss: 0.3886 - val_accuracy: 0.6818\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.4503 - accuracy: 0.7333 - val_loss: 0.4768 - val_accuracy: 0.6818\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4160 - accuracy: 0.7714 - val_loss: 0.4009 - val_accuracy: 0.6818\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.3792 - accuracy: 0.7429 - val_loss: 0.3012 - val_accuracy: 0.9545\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3830 - accuracy: 0.8381 - val_loss: 0.3437 - val_accuracy: 0.8182\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3310 - accuracy: 0.9333 - val_loss: 0.3284 - val_accuracy: 0.7273\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3097 - accuracy: 0.8381 - val_loss: 0.2416 - val_accuracy: 0.9545\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2583 - accuracy: 0.9714 - val_loss: 0.2143 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.2340 - accuracy: 0.9429 - val_loss: 0.2007 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2003 - accuracy: 0.9810 - val_loss: 0.2404 - val_accuracy: 0.9091\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.2141 - accuracy: 0.9333 - val_loss: 0.1783 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.2144 - accuracy: 0.9143 - val_loss: 0.1598 - val_accuracy: 0.9545\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.1660 - accuracy: 0.9619 - val_loss: 0.1283 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.1519 - accuracy: 0.9619 - val_loss: 0.1388 - val_accuracy: 0.9545\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.2113 - accuracy: 0.8952 - val_loss: 0.1068 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.1437 - accuracy: 0.9524 - val_loss: 0.1101 - val_accuracy: 0.9545\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.1403 - accuracy: 0.9619 - val_loss: 0.0865 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1289 - accuracy: 0.9619 - val_loss: 0.0786 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.1096 - accuracy: 0.9619 - val_loss: 0.0830 - val_accuracy: 0.9545\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.1121 - accuracy: 0.9524 - val_loss: 0.0681 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.1239 - accuracy: 0.9524 - val_loss: 0.0977 - val_accuracy: 0.9545\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.1180 - accuracy: 0.9524 - val_loss: 0.0902 - val_accuracy: 0.9545\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1361 - accuracy: 0.9333 - val_loss: 0.0596 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.1177 - accuracy: 0.9524 - val_loss: 0.0827 - val_accuracy: 0.9545\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.1005 - accuracy: 0.9524 - val_loss: 0.0507 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0959 - accuracy: 0.9524 - val_loss: 0.0479 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0999 - accuracy: 0.9619 - val_loss: 0.0457 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0970 - accuracy: 0.9619 - val_loss: 0.0535 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0838 - accuracy: 0.9810 - val_loss: 0.0470 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0921 - accuracy: 0.9714 - val_loss: 0.0443 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0805 - accuracy: 0.9810 - val_loss: 0.0502 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0794 - accuracy: 0.9810 - val_loss: 0.0414 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.0804 - accuracy: 0.9714 - val_loss: 0.0353 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0903 - accuracy: 0.9524 - val_loss: 0.1132 - val_accuracy: 0.9545\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.1543 - accuracy: 0.9238 - val_loss: 0.0333 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0949 - accuracy: 0.9429 - val_loss: 0.0428 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0894 - accuracy: 0.9714 - val_loss: 0.0538 - val_accuracy: 0.9545\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.1025 - accuracy: 0.9619 - val_loss: 0.0367 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0765 - accuracy: 0.9524 - val_loss: 0.0406 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0804 - accuracy: 0.9524 - val_loss: 0.0517 - val_accuracy: 0.9545\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0800 - accuracy: 0.9714 - val_loss: 0.0321 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0795 - accuracy: 0.9714 - val_loss: 0.0626 - val_accuracy: 0.9545\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0771 - accuracy: 0.9619 - val_loss: 0.0338 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.1140 - accuracy: 0.9524 - val_loss: 0.1322 - val_accuracy: 0.9545\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.1061 - accuracy: 0.9429 - val_loss: 0.0417 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.1441 - accuracy: 0.9429 - val_loss: 0.3108 - val_accuracy: 0.8182\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.2181 - accuracy: 0.9333 - val_loss: 0.2197 - val_accuracy: 0.8636\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.2692 - accuracy: 0.8952 - val_loss: 0.5338 - val_accuracy: 0.8182\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3478 - accuracy: 0.8571 - val_loss: 0.5145 - val_accuracy: 0.7273\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.4823 - accuracy: 0.8476 - val_loss: 0.3834 - val_accuracy: 0.8182\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.4501 - accuracy: 0.8286 - val_loss: 0.0396 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3960 - accuracy: 0.8571 - val_loss: 0.0438 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.3187 - accuracy: 0.8667 - val_loss: 0.3948 - val_accuracy: 0.8182\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.2577 - accuracy: 0.9048 - val_loss: 0.1863 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.2451 - accuracy: 0.9048 - val_loss: 0.1192 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.1334 - accuracy: 0.9714 - val_loss: 0.1066 - val_accuracy: 0.9545\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.1141 - accuracy: 0.9714 - val_loss: 0.0711 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.1075 - accuracy: 0.9524 - val_loss: 0.0640 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0885 - accuracy: 0.9714 - val_loss: 0.0499 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0878 - accuracy: 0.9619 - val_loss: 0.0538 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.0827 - accuracy: 0.9810 - val_loss: 0.0487 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0798 - accuracy: 0.9714 - val_loss: 0.0412 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0801 - accuracy: 0.9810 - val_loss: 0.0471 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0772 - accuracy: 0.9714 - val_loss: 0.0290 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.0841 - accuracy: 0.9619 - val_loss: 0.0534 - val_accuracy: 0.9545\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0846 - accuracy: 0.9619 - val_loss: 0.0376 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0963 - accuracy: 0.9619 - val_loss: 0.0476 - val_accuracy: 0.9545\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.1424 - accuracy: 0.9333 - val_loss: 0.0495 - val_accuracy: 0.9545\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.1456 - accuracy: 0.9524 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0833 - accuracy: 0.9714 - val_loss: 0.0846 - val_accuracy: 0.9545\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0800 - accuracy: 0.9714 - val_loss: 0.0360 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.1600 - accuracy: 0.9429 - val_loss: 0.0516 - val_accuracy: 0.9545\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1521 - accuracy: 0.9333 - val_loss: 0.0996 - val_accuracy: 0.9545\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0705 - accuracy: 0.9619 - val_loss: 0.0326 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.1215 - accuracy: 0.9524 - val_loss: 0.0359 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0752 - accuracy: 0.9714 - val_loss: 0.0778 - val_accuracy: 0.9545\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0838 - accuracy: 0.9524 - val_loss: 0.0265 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.0788 - accuracy: 0.9524 - val_loss: 0.0319 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0706 - accuracy: 0.9810 - val_loss: 0.0385 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.0668 - accuracy: 0.9810 - val_loss: 0.0273 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0704 - accuracy: 0.9619 - val_loss: 0.0305 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.0716 - accuracy: 0.9810 - val_loss: 0.0210 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.1031 - accuracy: 0.9524 - val_loss: 0.0366 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.1377 - accuracy: 0.9429 - val_loss: 0.0472 - val_accuracy: 0.9545\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.1079 - accuracy: 0.9714 - val_loss: 0.0214 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0746 - accuracy: 0.9619 - val_loss: 0.1037 - val_accuracy: 0.9545\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1120 - accuracy: 0.9429 - val_loss: 0.0196 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0790 - accuracy: 0.9714 - val_loss: 0.0386 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.1134 - accuracy: 0.9429 - val_loss: 0.0309 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0979 - accuracy: 0.9619 - val_loss: 0.0230 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.0772 - accuracy: 0.9714 - val_loss: 0.1404 - val_accuracy: 0.9545\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.1284 - accuracy: 0.9333 - val_loss: 0.0208 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.1232 - accuracy: 0.9524 - val_loss: 0.0373 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.1324 - accuracy: 0.9429 - val_loss: 0.0299 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "valSet = (validationF, validationLE)\n",
    "history = model.fit(trainF, trainLE, epochs=100, validation_data=valSet) #training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [8.555513381958008, 2.369525671005249, 1.480462908744812, 1.0553436279296875, 0.6477057337760925, 0.7159822583198547, 0.6688159108161926, 0.45027032494544983, 0.41601550579071045, 0.379230797290802, 0.38300424814224243, 0.3310237228870392, 0.3096552789211273, 0.25826162099838257, 0.2340046465396881, 0.20032259821891785, 0.214073047041893, 0.21435096859931946, 0.1660405993461609, 0.15191741287708282, 0.21130876243114471, 0.1436929851770401, 0.1403156816959381, 0.12893062829971313, 0.10964585095643997, 0.11211863160133362, 0.12394369393587112, 0.11803032457828522, 0.13611483573913574, 0.11770112067461014, 0.10045760869979858, 0.09591630846261978, 0.09988513588905334, 0.09700682759284973, 0.08383399993181229, 0.09207324683666229, 0.08052535355091095, 0.07944547384977341, 0.08043425530195236, 0.09030134975910187, 0.15426385402679443, 0.09490813314914703, 0.0894114077091217, 0.10249212384223938, 0.07650894671678543, 0.08036178350448608, 0.07996100187301636, 0.07950226962566376, 0.07712912559509277, 0.11399585753679276, 0.10606193542480469, 0.14405609667301178, 0.2180660218000412, 0.2692054808139801, 0.34782668948173523, 0.48233577609062195, 0.45010828971862793, 0.39603111147880554, 0.31867626309394836, 0.25771284103393555, 0.2450544238090515, 0.1334373652935028, 0.11409591138362885, 0.10752584040164948, 0.08853653818368912, 0.08783333003520966, 0.08269980549812317, 0.07977328449487686, 0.08005329221487045, 0.07723065465688705, 0.08411240577697754, 0.0846206471323967, 0.09629747271537781, 0.14241814613342285, 0.1456150859594345, 0.08326472342014313, 0.08003391325473785, 0.1599520593881607, 0.15213479101657867, 0.07052363455295563, 0.12148880958557129, 0.07517003268003464, 0.08384212851524353, 0.0788118913769722, 0.07058180868625641, 0.06678248941898346, 0.07040891796350479, 0.07158207893371582, 0.10310140252113342, 0.13772320747375488, 0.10787098109722137, 0.07463372498750687, 0.11200068891048431, 0.07897595316171646, 0.11336757242679596, 0.09787464141845703, 0.07716991752386093, 0.12836749851703644, 0.12317542731761932, 0.13241611421108246], 'accuracy': [0.34285715222358704, 0.41904762387275696, 0.523809552192688, 0.6190476417541504, 0.7428571581840515, 0.6761904954910278, 0.6666666865348816, 0.7333333492279053, 0.7714285850524902, 0.7428571581840515, 0.8380952477455139, 0.9333333373069763, 0.8380952477455139, 0.9714285731315613, 0.9428571462631226, 0.9809523820877075, 0.9333333373069763, 0.9142857193946838, 0.961904764175415, 0.961904764175415, 0.8952381014823914, 0.9523809552192688, 0.961904764175415, 0.961904764175415, 0.961904764175415, 0.9523809552192688, 0.9523809552192688, 0.9523809552192688, 0.9333333373069763, 0.9523809552192688, 0.9523809552192688, 0.9523809552192688, 0.961904764175415, 0.961904764175415, 0.9809523820877075, 0.9714285731315613, 0.9809523820877075, 0.9809523820877075, 0.9714285731315613, 0.9523809552192688, 0.9238095283508301, 0.9428571462631226, 0.9714285731315613, 0.961904764175415, 0.9523809552192688, 0.9523809552192688, 0.9714285731315613, 0.9714285731315613, 0.961904764175415, 0.9523809552192688, 0.9428571462631226, 0.9428571462631226, 0.9333333373069763, 0.8952381014823914, 0.8571428656578064, 0.8476190567016602, 0.8285714387893677, 0.8571428656578064, 0.8666666746139526, 0.9047619104385376, 0.9047619104385376, 0.9714285731315613, 0.9714285731315613, 0.9523809552192688, 0.9714285731315613, 0.961904764175415, 0.9809523820877075, 0.9714285731315613, 0.9809523820877075, 0.9714285731315613, 0.961904764175415, 0.961904764175415, 0.961904764175415, 0.9333333373069763, 0.9523809552192688, 0.9714285731315613, 0.9714285731315613, 0.9428571462631226, 0.9333333373069763, 0.961904764175415, 0.9523809552192688, 0.9714285731315613, 0.9523809552192688, 0.9523809552192688, 0.9809523820877075, 0.9809523820877075, 0.961904764175415, 0.9809523820877075, 0.9523809552192688, 0.9428571462631226, 0.9714285731315613, 0.961904764175415, 0.9428571462631226, 0.9714285731315613, 0.9428571462631226, 0.961904764175415, 0.9714285731315613, 0.9333333373069763, 0.9523809552192688, 0.9428571462631226], 'val_loss': [1.5456135272979736, 1.7406045198440552, 0.8475101590156555, 0.6289691925048828, 0.8590659499168396, 0.6140516400337219, 0.38858166337013245, 0.4767874479293823, 0.4009282886981964, 0.3012261688709259, 0.34374159574508667, 0.3284447491168976, 0.24164900183677673, 0.21427789330482483, 0.2007235884666443, 0.24035248160362244, 0.17832590639591217, 0.1597527414560318, 0.128335103392601, 0.1387643963098526, 0.10680258274078369, 0.11010842025279999, 0.08646795153617859, 0.07862737774848938, 0.08301008492708206, 0.06813698261976242, 0.09767577797174454, 0.09022554755210876, 0.05957914888858795, 0.08267010003328323, 0.05069279298186302, 0.047919001430273056, 0.04572213068604469, 0.053463567048311234, 0.047013066709041595, 0.044253453612327576, 0.050173476338386536, 0.04135468229651451, 0.03529631346464157, 0.11315508186817169, 0.033297326415777206, 0.0427757166326046, 0.053845908492803574, 0.036748599261045456, 0.0406312458217144, 0.05168086662888527, 0.032101426273584366, 0.06258334964513779, 0.03380311280488968, 0.13217322528362274, 0.041707754135131836, 0.3108353614807129, 0.2196551263332367, 0.5338432788848877, 0.5145474076271057, 0.3834036886692047, 0.03957708179950714, 0.043830059468746185, 0.39480695128440857, 0.18631187081336975, 0.11916472762823105, 0.10662507265806198, 0.07109501957893372, 0.06399030238389969, 0.04985092952847481, 0.053789541125297546, 0.048684027045965195, 0.041174713522195816, 0.04705878347158432, 0.029032278805971146, 0.05338390916585922, 0.03758200630545616, 0.04757076874375343, 0.04946179687976837, 0.027049727737903595, 0.08461172133684158, 0.03601562976837158, 0.05162006989121437, 0.09955385327339172, 0.032579369843006134, 0.035900358110666275, 0.07779849320650101, 0.026489796116948128, 0.03188890591263771, 0.038459811359643936, 0.027336327359080315, 0.03050045855343342, 0.021025381982326508, 0.03655911982059479, 0.047192271798849106, 0.021412957459688187, 0.10373928397893906, 0.01958097331225872, 0.03862123563885689, 0.030916953459382057, 0.022970734164118767, 0.14037981629371643, 0.020752636715769768, 0.03734913095831871, 0.029889661818742752], 'val_accuracy': [0.3181818127632141, 0.3636363744735718, 0.6363636255264282, 0.6818181872367859, 0.6818181872367859, 0.6818181872367859, 0.6818181872367859, 0.6818181872367859, 0.6818181872367859, 0.9545454382896423, 0.8181818127632141, 0.7272727489471436, 0.9545454382896423, 1.0, 1.0, 0.9090909361839294, 1.0, 0.9545454382896423, 1.0, 0.9545454382896423, 1.0, 0.9545454382896423, 1.0, 1.0, 0.9545454382896423, 1.0, 0.9545454382896423, 0.9545454382896423, 1.0, 0.9545454382896423, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9545454382896423, 1.0, 1.0, 0.9545454382896423, 1.0, 1.0, 0.9545454382896423, 1.0, 0.9545454382896423, 1.0, 0.9545454382896423, 1.0, 0.8181818127632141, 0.8636363744735718, 0.8181818127632141, 0.7272727489471436, 0.8181818127632141, 1.0, 1.0, 0.8181818127632141, 1.0, 1.0, 0.9545454382896423, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9545454382896423, 1.0, 0.9545454382896423, 0.9545454382896423, 1.0, 0.9545454382896423, 1.0, 0.9545454382896423, 0.9545454382896423, 1.0, 1.0, 0.9545454382896423, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9545454382896423, 1.0, 0.9545454382896423, 1.0, 1.0, 1.0, 1.0, 0.9545454382896423, 1.0, 1.0, 1.0]}\n"
     ]
    }
   ],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.3587334e-03 9.9351007e-01 4.1311719e-03]\n",
      " [2.9925218e-07 9.1631971e-03 9.9083650e-01]\n",
      " [9.9849975e-01 1.5001233e-03 1.7280890e-07]\n",
      " [9.3841320e-03 9.8753786e-01 3.0779582e-03]\n",
      " [1.3501555e-09 2.8014177e-04 9.9971980e-01]\n",
      " [9.9942207e-01 5.7798630e-04 4.8979896e-08]\n",
      " [1.4660729e-03 9.9093986e-01 7.5940830e-03]\n",
      " [8.8877739e-10 1.7091075e-04 9.9982905e-01]\n",
      " [9.9817872e-01 1.8210475e-03 2.2329669e-07]\n",
      " [3.3260959e-03 9.9283069e-01 3.8431936e-03]]\n"
     ]
    }
   ],
   "source": [
    "labelPred = model.predict(testF)\n",
    "print(labelPred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2]\n"
     ]
    }
   ],
   "source": [
    "labelTestClass = np.argmax(testLE, axis=1)\n",
    "labelPredClass = np.argmax(labelPred, axis=1)\n",
    "print(labelTestClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      1.00      1.00         8\n",
      "           2       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        23\n",
      "   macro avg       1.00      1.00      1.00        23\n",
      "weighted avg       1.00      1.00      1.00        23\n",
      "\n",
      "[[7 0 0]\n",
      " [0 8 0]\n",
      " [0 0 8]]\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(labelTestClass, labelPredClass)\n",
    "confMatrix = confusion_matrix(labelTestClass, labelPredClass)\n",
    "print(report)\n",
    "print(confMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='MAE (training data)')\n",
    "plt.plot(history.history['val_loss'], label='MAE (validation data)')\n",
    "plt.title('MAE for Chennai Reservoir Levels')\n",
    "plt.ylabel('MAE value')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "#cuentame que mas ha pasado mijo\n",
    "#aca hablando con mi viejo"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a749ce9e7f55799ed652412e343278838c2c048e73833d9c0011e1dd1316e4b4"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
